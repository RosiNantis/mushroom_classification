{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make a list of the mushrooms names\n",
    "directory = 'kaggle/sample_data/'\n",
    "folder_list= [f for f in listdir(directory)]\n",
    "# folder_list.remove('mushroom_sample')\n",
    "# folder_list.remove('mushroom_sample.zip')\n",
    "# folder_list.remove('.DS_Store')\n",
    "# folder_list.remove('data_pool')\n",
    "folder_list\n",
    "CLASSES = dict(zip(folder_list, range(len(folder_list)))) # dictionary of the mushrooms with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: unpickle and connect\n",
    "def unpickle(directory, category ):\n",
    "    \"\"\"\n",
    "    This functions takes the data from a directory that have been\n",
    "    downsized in banches ang gives back the X,y as arrays.\n",
    "    \"\"\"\n",
    "    table_mushrooms_downsized = []\n",
    "    label_mushrooms = []\n",
    "    for mushroom in CLASSES:\n",
    "\n",
    "        dir = directory + mushroom + '/X_' + category + '_resized'\n",
    "        with open(dir, \"rb\") as fp:  X_resized = pickle.load(fp)\n",
    "        table_mushrooms_downsized.append(X_resized)\n",
    "        label = np.full((1, len(X_resized)), get_label(mushroom))#.ravel()\n",
    "        label_mushrooms = np.append(label_mushrooms,label)\n",
    "\n",
    "    # flatten the nested list into a 1D list\n",
    "    mushrooms_downsized = list(itertools.chain(*table_mushrooms_downsized))\n",
    "    return mushrooms_downsized, label_mushrooms\n",
    "\n",
    "    if len(mushrooms_downsized) == len(label):\n",
    "\n",
    "    #     #Check if the number of pictures and labels are the same.\n",
    "        X = np.asarray(mushrooms_downsized)\n",
    "        y = np.asarray(label_mushrooms)\n",
    "\n",
    "    return X, y\n",
    "for ca in [\"valid\",\"test\",\"train\"]:\n",
    "    category = ca\n",
    "    X, y = unpickle(directory='/kaggle/sample_data/', category = category)\n",
    "    directory = '/kaggle/working/'\n",
    "\n",
    "\n",
    "    with open(directory + \"X\" + category, \"wb\") as fp: pickle.dump(X, fp)\n",
    "    with open(directory + \"y\" + category, \"wb\") as fp: pickle.dump(y, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the samples and labels together. Since it \n",
    "shuffler = np.random.permutation(len(X))\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "Xtrain = X[shuffler]\n",
    "y= y[shuffler]\n",
    "# one-hot-encode labels\n",
    "ytrain = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image # Keras own inbuild image class\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "def model_ResNet50V2(CLASSES = CLASSES,learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    This function returns a ResNet50V2 model with the last\n",
    "    layer removed.\n",
    "    \"\"\"\n",
    "    K.clear_session() # Always clear the session!\n",
    "\n",
    "    base_model = ResNet50V2(\n",
    "        weights='imagenet', \n",
    "        pooling='avg',      # applies global average pooling to the output of the last conv layer (like a flattening)\n",
    "        include_top=False,   # !!!!! we only want to have the base, not the final dense layers \n",
    "        input_shape=(224, 224, 3)  \n",
    "    )\n",
    "    base_model.trainable = False # To freeze the model\n",
    "    # Start building on top of the model\n",
    "    model = keras.Sequential() # defining a new model\n",
    "    model.add(base_model) # adding in the pretrained model without the fully connected layer\n",
    "    model.add(keras.layers.Dense(64, activation='relu')) # adding in additional layers\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(128, activation='relu')) # adding in additional layers\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(len(CLASSES), activation='softmax')) #!!! Final layer with a length of 2, and softmax activation \n",
    "    # have a look at the trainable and non-trainable params statistic\n",
    "    model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=[keras.metrics.categorical_accuracy])\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_ResNet50V2(X, y,epochs = 200, batch_size =500,sav = True):\n",
    "    \"\"\"\n",
    "    This function fits the model on the training data.\n",
    "    \"\"\"\n",
    "    # observe the validation loss and stop when it does not improve after 3 iterations\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "    history = model.fit(X, y, \n",
    "              epochs=epochs, \n",
    "              verbose=2,\n",
    "              batch_size=batch_size, \n",
    "              callbacks=[callback],\n",
    "              # use 30% of the data for validation\n",
    "              validation_split=0.3)\n",
    "    # save model\n",
    "    if sav == True:\n",
    "        model.save('/kaggle/working/ResNet50V2_RGB_300fot_SD.h5')\n",
    "        \n",
    "    return history\n",
    "model = model_ResNet50V2()\n",
    "\n",
    "history = fit_ResNet50V2(Xtrain, ytrain, epochs = 200, batch_size =300)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
