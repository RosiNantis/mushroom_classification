{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten,\\\n",
    "BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_files_names(directory):\n",
    "    subfolders_path = [ f.name for f in os.scandir(directory) if f.is_dir() ]\n",
    "    return subfolders_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of the base folder\n",
    "dir = 'data/clean_data/'\n",
    "# Create a dictionary with mashrooms and labels\n",
    "CLASSES = dict(zip(fetch_files_names(dir), np.arange(0, len(fetch_files_names(dir)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the directory that includes folders of images and return three files split in train test validation\n",
    "\n",
    "def split_data(dir = dir, output = dir + \"/../output\"):\n",
    "    \"\"\"\n",
    "    Split data in train, test, validataion\n",
    "    \"\"\"\n",
    "    splitfolders.ratio(dir , output=output, seed=1337, ratio=(.75, 0.15,0.1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 26817 files [02:41, 166.13 files/s]\n"
     ]
    }
   ],
   "source": [
    "split_data()\n",
    "train_path = dir + \"/../output\" + '/train/'\n",
    "test_path = dir + \"/../output\" + '/test/'\n",
    "valid_path = dir + \"/../output\" + '/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16094 images belonging to 26 classes.\n",
      "Found 4009 images belonging to 26 classes.\n",
      "Found 2705 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare data for the model in batches to avoid RAM problems\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0,validation_split=0.2) \n",
    "train_batches = train_datagen.flow_from_directory(directory=train_path, \\\n",
    "target_size=(224,224), classes=CLASSES, batch_size=64,subset='training')\n",
    "\n",
    "validation_batches = train_datagen.flow_from_directory(directory=train_path, \\\n",
    "target_size=(224,224), classes=CLASSES, batch_size=64,subset='validation')\n",
    "\n",
    "test_batches = ImageDataGenerator(rescale=1.0/255.0).flow_from_directory(\\\n",
    "directory=test_path, target_size=(224,224), classes=CLASSES, \\\n",
    "batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image # Keras own inbuild image class\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "def model_ResNet50V2( learning_rate=0.001, cl = CLASSES):\n",
    "    \"\"\"\n",
    "    This function returns a ResNet50V2 model with the last\n",
    "    layer removed.\n",
    "    \"\"\"\n",
    "    K.clear_session() # Always clear the session!\n",
    "\n",
    "    base_model = ResNet50V2(\n",
    "        weights='imagenet', \n",
    "        pooling='avg',      # applies global average pooling to the output of the last conv layer (like a flattening)\n",
    "        include_top=False,   # !!!!! we only want to have the base, not the final dense layers \n",
    "        input_shape=(224, 224, 3)  \n",
    "    )\n",
    "    base_model.trainable = False # To freeze the model\n",
    "    # Start building on top of the model\n",
    "    model = keras.Sequential() # defining a new model\n",
    "    model.add(base_model) # adding in the pretrained model without the fully connected layer\n",
    "    model.add(keras.layers.Dense(64, activation='relu')) # adding in additional layers\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(128, activation='relu')) # adding in additional layers\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(len(cl), activation='softmax')) #!!! Final layer with a length of 2, and softmax activation \n",
    "    # have a look at the trainable and non-trainable params statistic\n",
    "    model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=[keras.metrics.categorical_accuracy])\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_ResNet50V2(train_batches=train_batches,validation_data =validation_batches,epochs = 200, sav = True):\n",
    "    \"\"\"\n",
    "    This function fits the model on the training data.\n",
    "    \"\"\"\n",
    "    # observe the validation loss and stop when it does not improve after 3 iterations\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "    history = model.fit( x=train_batches,\n",
    "            epochs=epochs, \n",
    "            verbose=1, \n",
    "            callbacks=[callback],\n",
    "            validation_data = validation_data, )\n",
    "    \n",
    "    # save model\n",
    "    if sav == True:\n",
    "        model.save('models/ResNet50V2_test.h5') \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ResNet50V2(learning_rate=0.001)\n",
    "model, history = fit_ResNet50V2(epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, decode_predictions, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image # Keras own inbuild image class\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "def model_InceptionResNetV2( learning_rate=0.001, cl = CLASSES):\n",
    "    \"\"\"\n",
    "    This function returns a ResNet50V2 model with the last\n",
    "    layer removed.\n",
    "    \"\"\"\n",
    "    K.clear_session() # Always clear the session!\n",
    "\n",
    "    base_model = InceptionResNetV2(\n",
    "        weights='imagenet', \n",
    "        pooling='avg',      # applies global average pooling to the output of the last conv layer (like a flattening)\n",
    "        include_top=False,   # !!!!! we only want to have the base, not the final dense layers \n",
    "        input_shape=(224, 224, 3)  \n",
    "    )\n",
    "    base_model.trainable = False # To freeze the model\n",
    "    # Start building on top of the model\n",
    "    model = keras.Sequential() # defining a new model\n",
    "    model.add(base_model) # adding in the pretrained model without the fully connected layer\n",
    "    model.add(keras.layers.Dense(64, activation='relu')) # adding in additional layers\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(128, activation='relu')) # adding in additional layers\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(len(cl), activation='softmax')) #!!! Final layer with a length of 2, and softmax activation \n",
    "    # have a look at the trainable and non-trainable params statistic\n",
    "    model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=[keras.metrics.categorical_accuracy])\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_ResNet50V2(train_batches=train_batches,validation_data =validation_batches,epochs = 200, sav = True):\n",
    "    \"\"\"\n",
    "    This function fits the model on the training data.\n",
    "    \"\"\"\n",
    "    # observe the validation loss and stop when it does not improve after 3 iterations\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "    history = model.fit( x=train_batches,\n",
    "            epochs=epochs, \n",
    "            verbose=1, \n",
    "            callbacks=[callback],\n",
    "            validation_data = validation_data, )\n",
    "    \n",
    "    # save model\n",
    "    if sav == True:\n",
    "        model.save('models/ResNet50V2_test.h5') \n",
    "    return model, history\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
