{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten,\\\n",
    "BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.5.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data/mushrooms/first_batch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/mushrooms/first_batch/training_data',\n",
       " 'data/mushrooms/first_batch/Auricularia_auricula-judae',\n",
       " 'data/mushrooms/first_batch/test_data',\n",
       " 'data/mushrooms/first_batch/Cuphophyllus_virgineus',\n",
       " 'data/mushrooms/first_batch/Bjerkandera_adusta',\n",
       " 'data/mushrooms/first_batch/valid_set',\n",
       " 'data/mushrooms/first_batch/Coprinellus_micaceus',\n",
       " 'data/mushrooms/first_batch/Clitocybe_nebularis']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subfolders_path = [ f.path for f in os.scandir(\"data/mushrooms/first_batch/\") if f.is_dir() ]\n",
    "subfolders_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training_data',\n",
       " 'Auricularia_auricula-judae',\n",
       " 'test_data',\n",
       " 'Cuphophyllus_virgineus',\n",
       " 'Bjerkandera_adusta',\n",
       " 'valid_set',\n",
       " 'Coprinellus_micaceus',\n",
       " 'Clitocybe_nebularis']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subfolders = [ f.name for f in os.scandir(\"data/mushrooms/first_batch/\") if f.is_dir() ]\n",
    "subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 5598 files [00:19, 293.69 files/s]\n"
     ]
    }
   ],
   "source": [
    "# give the directory that includes folders of images and return three files split in train test validation\n",
    "dir = 'data/mushrooms/second_batch/'\n",
    "splitfolders.ratio(dir , output=dir + \"output\", seed=1337, ratio=(.75, 0.15,0.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/08/6zrs8w253573k0k0yjq1w49c0000gn/T/ipykernel_41905/2415424161.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subfolders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/08/6zrs8w253573k0k0yjq1w49c0000gn/T/ipykernel_46056/3286974922.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subfolders' is not defined"
     ]
    }
   ],
   "source": [
    "CLASSES = dict(zip(subfolders, np.arange(0, len(subfolders))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirectory = subfolders[0]\n",
    "onlyfiles = [f for f in listdir(subdirectory) if isfile(join(subdirectory, f))]\n",
    "#onlyfiles.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(key ,class_mush ):\n",
    "    \"\"\"\n",
    "    You can get the labeled name of the mushroom by giving \n",
    "    the index or the index by giving the key\n",
    "    \"\"\"\n",
    "    if type(key) == str:\n",
    "        return class_mush[key]\n",
    "    elif type(key) == int:\n",
    "        return list(class_mush.keys())[list(class_mush.values()).index(key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_files_paths(directory):\n",
    "    subfolders_path = [ f.path for f in os.scandir(directory) if f.is_dir() ]\n",
    "    CLASSES = dict(zip(subfolders_path, np.arange(0, len(subfolders_path))))\n",
    "    return subfolders_path, CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_image(subdirectory):\n",
    "    onlyfiles = [f for f in listdir(subdirectory) if isfile(join(subdirectory, f))]\n",
    "    label = np.full((1, len(onlyfiles)), get_label(onlyfiles))#.ravel()\n",
    "    return onlyfiles, label\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_reshape(directory, new_size = (28,28), gray =False):\n",
    "    \"\"\"\n",
    "    give the list of photos with the correct pixel size you want to \n",
    "    downsize. If you want Gray then write True.\n",
    "    \"\"\"\n",
    "    items_resized  =[]\n",
    "    pictures = []\n",
    "    labels = []\n",
    "    mapping = {'plants' : 0,'coins' : 1,'faces' : 2,'cups' : 3,'glasses' : 4,'pens' : 5,'gestures' : 6,'cutlery' : 7,'plates' : 8, \n",
    "                'nail_polishes' : 9  ,'shoes' : 10 \n",
    "                }\n",
    "    onlyfolders = [f for f in listdir(directory)]\n",
    "    for idx, folder in enumerate(onlyfolders[1:]):\n",
    "        pictures = [f for f in listdir(directory + folder) if isfile(join(directory + folder , f))]\n",
    "        for idx, picture in enumerate(pictures):\n",
    "            item = cv2.imread(directory + folder +'/'+ picture )\n",
    "            labels.append(mapping[folder])\n",
    "            \n",
    "            if gray == True:\n",
    "                item_gray = cv2.cvtColor(item, cv2.COLOR_BGR2GRAY)\n",
    "                item_resized_gray = resize(item_gray, new_size)\n",
    "                items_resized.append(item_resized_gray)\n",
    "            else:\n",
    "                item_resized_colored = resize(item, new_size)\n",
    "                items_resized.append(item_resized_colored)\n",
    "    return items_resized, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/mushrooms/second_batch/output/train/'\n",
    "test_path = 'data/mushrooms/second_batch/output/test/'\n",
    "valid_path = 'data/mushrooms/second_batch/output/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_files_paths(directory):\n",
    "    subfolders_path = [ f.path for f in os.scandir(directory) if f.is_dir() ]\n",
    "    return subfolders_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/mushrooms/second_batch/output/test',\n",
       " 'data/mushrooms/second_batch/output/train',\n",
       " 'data/mushrooms/second_batch/output/val']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_files_paths('data/mushrooms/second_batch/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/mushrooms/second_batch/output/train/'\n",
    "test_path = 'data/mushrooms/second_batch/output/test/'\n",
    "valid_path = 'data/mushrooms/second_batch/output/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3359 images belonging to 5 classes.\n",
      "Found 837 images belonging to 5 classes.\n",
      "Found 565 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0,validation_split=0.2) \n",
    "CLASSES = ['Daedaleopsis_confragosa', 'Fomes_fomentarius','Fomitopsis_pinicola','Ganoderma_applanatum','Gymnopilus_penetrans' ]\n",
    "train_batches = train_datagen.flow_from_directory(directory=train_path, \\\n",
    "target_size=(224,224), classes=CLASSES, batch_size=64,subset='training')\n",
    "\n",
    "validation_batches = train_datagen.flow_from_directory(directory=train_path, \\\n",
    "target_size=(224,224), classes=CLASSES, batch_size=64,subset='validation')\n",
    "\n",
    "test_batches = ImageDataGenerator(rescale=1.0/255.0).flow_from_directory(\\\n",
    "directory=test_path, target_size=(224,224), classes=CLASSES, \\\n",
    "batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image # Keras own inbuild image class\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "def model_ResNet50V2( learning_rate=0.001, cl = CLASSES):\n",
    "    \"\"\"\n",
    "    This function returns a ResNet50V2 model with the last\n",
    "    layer removed.\n",
    "    \"\"\"\n",
    "    K.clear_session() # Always clear the session!\n",
    "\n",
    "    base_model = ResNet50V2(\n",
    "        weights='imagenet', \n",
    "        pooling='avg',      # applies global average pooling to the output of the last conv layer (like a flattening)\n",
    "        include_top=False,   # !!!!! we only want to have the base, not the final dense layers \n",
    "        input_shape=(224, 224, 3)  \n",
    "    )\n",
    "    base_model.trainable = False # To freeze the model\n",
    "    # Start building on top of the model\n",
    "    model = keras.Sequential() # defining a new model\n",
    "    model.add(base_model) # adding in the pretrained model without the fully connected layer\n",
    "    model.add(keras.layers.Dense(64, activation='relu')) # adding in additional layers\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(128, activation='relu')) # adding in additional layers\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(5, activation='softmax')) #!!! Final layer with a length of 2, and softmax activation \n",
    "    # have a look at the trainable and non-trainable params statistic\n",
    "    model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=[keras.metrics.categorical_accuracy])\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_ResNet50V2(train_batches,validation_data ,epochs = 200, sav = True):\n",
    "    \"\"\"\n",
    "    This function fits the model on the training data.\n",
    "    \"\"\"\n",
    "    # observe the validation loss and stop when it does not improve after 3 iterations\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "    history = model.fit( x=train_batches,\n",
    "            epochs=epochs, \n",
    "            verbose=1, \n",
    "            callbacks=[callback],\n",
    "            validation_data = validation_data, )\n",
    "    \n",
    "    # save model\n",
    "    if sav == True:\n",
    "        model.save('models/ResNet50V2_test.h5')\n",
    "        \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,704,901\n",
      "Trainable params: 140,101\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 531s 10s/step - loss: 1.1090 - categorical_accuracy: 0.5389 - val_loss: 0.8853 - val_categorical_accuracy: 0.6428\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 452s 9s/step - loss: 0.7985 - categorical_accuracy: 0.6946 - val_loss: 0.8571 - val_categorical_accuracy: 0.6703\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 401s 8s/step - loss: 0.6643 - categorical_accuracy: 0.7386 - val_loss: 0.8383 - val_categorical_accuracy: 0.6679\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 345s 7s/step - loss: 0.5879 - categorical_accuracy: 0.7734 - val_loss: 0.8255 - val_categorical_accuracy: 0.7013\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 344s 7s/step - loss: 0.5044 - categorical_accuracy: 0.8089 - val_loss: 0.8348 - val_categorical_accuracy: 0.6953\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 343s 6s/step - loss: 0.4298 - categorical_accuracy: 0.8443 - val_loss: 0.8589 - val_categorical_accuracy: 0.6894\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 343s 6s/step - loss: 0.3708 - categorical_accuracy: 0.8631 - val_loss: 0.8444 - val_categorical_accuracy: 0.7001\n"
     ]
    }
   ],
   "source": [
    "model = model_ResNet50V2(cl =CLASSES)\n",
    "history = fit_ResNet50V2(train_batches,validation_batches, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
